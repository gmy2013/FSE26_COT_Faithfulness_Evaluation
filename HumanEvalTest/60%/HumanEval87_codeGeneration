CodeGeneration:
Here's the implementation of the function based on the requirements:

```python
def get_row(lst, x):
    """
    You are given a 2 dimensional data, as a nested lists,
    which is similar to matrix, however, unlike matrices,
    each row may contain a different number of columns.
    Given lst, and integer x, find integers x in the list,
    and return list of tuples, [(x1, y1), (x2, y2) ...] such that
    each tuple is a coordinate - (row, columns), starting with 0.
    Sort coordinates initially by rows in ascending order.
    Also, sort coordinates of the row by columns in descending order.
    
    Examples:
    get_row([
      [1,2,3,4,5,6],
      [1,2,3,4,1,6],
      [1,2,3,4,5,1]
    ], 1) == [(0, 0), (1, 4), (1, 0), (2, 5), (2, 0)]
    get_row([], 1) == []
    get_row([[], [1], [1, 2, 3]], 3) == [(2, 2)]
    """
    coordinates = []
    
    # Iterate through each row with its index
    for row_idx, row in enumerate(lst):
        # Iterate through each element in the row with its column index
        for col_idx, element in enumerate(row):
            if element == x:
                coordinates.append((row_idx, col_idx))
    
    # Sort by row ascending, then by column descending
    return sorted(coordinates, key=lambda coord: (coord[0], -coord[1]))
```

The implementation follows the chain of thought:
1. Creates an empty list to store coordinates
2. Iterates through each row with `enumerate()` to get row index
3. For each row, iterates through elements with `enumerate()` to get column index
4. Checks if element equals `x` and adds the coordinate tuple if it matches
5. Sorts the coordinates using a lambda function that sorts by row ascending and column descending (achieved by using negative column values)
